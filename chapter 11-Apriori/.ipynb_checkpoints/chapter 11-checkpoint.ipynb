{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7590fa",
   "metadata": {},
   "source": [
    "### 关联分析（关联规则学习）含义：从大规模数据中寻找物品间的联系"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03adae",
   "metadata": {},
   "source": [
    "##### Apriori算法：\n",
    "###### 优点：易于编码实现\n",
    "###### 缺点：在大数据集上运行较慢\n",
    "###### 适用数据类型：数值型或者标称型\n",
    "##### 一些概念：\n",
    "###### 频繁项集：经常出现在一块的物品的集合\n",
    "###### 关联规则：暗示两种物品之间存在很强的关系\n",
    "###### 如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47baab8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>交易号码</th>\n",
       "      <th>商品</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>豆奶、莴苣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>莴苣、尿布、葡萄酒、甜菜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>豆奶、尿布、葡萄酒、橙汁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>莴苣、豆奶、尿布、葡萄酒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>莴苣、豆奶、尿布、橙汁</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   交易号码            商品\n",
       "0     0         豆奶、莴苣\n",
       "1     1  莴苣、尿布、葡萄酒、甜菜\n",
       "2     2  豆奶、尿布、葡萄酒、橙汁\n",
       "3     3  莴苣、豆奶、尿布、葡萄酒\n",
       "4     4   莴苣、豆奶、尿布、橙汁"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import *\n",
    "import pandas as pd\n",
    "\n",
    "dataId=[i for i in range(5)]\n",
    "dataValue=['豆奶、莴苣','莴苣、尿布、葡萄酒、甜菜','豆奶、尿布、葡萄酒、橙汁','莴苣、豆奶、尿布、葡萄酒','莴苣、豆奶、尿布、橙汁']\n",
    "data=pd.DataFrame()\n",
    "data['交易号码']=dataId\n",
    "data['商品']=dataValue\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43260955",
   "metadata": {},
   "source": [
    "##### 上述数据中，葡萄酒、豆奶、尿布就是一组频繁项集，可以观察出买了尿布的人很可能会买葡萄酒"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c421a4fd",
   "metadata": {},
   "source": [
    "##### 频繁项集中频繁的度量单位：支持度和可信度\n",
    "##### 一个频繁项集的支持度被定义为：数据集中包含该项集记录所占比例，是针对项集的\n",
    "##### 例如上述数据中豆奶的支持度为4/5\n",
    "##### 可信度（置信度）：针对一条关联规则来的，这条关联规则的可信度被定义为两个支持度的比值（类似于条件概率）\n",
    "##### 例如关联规则尿布->葡萄酒的置信度为:支持度（尿布、葡萄酒）/支持度（尿布）\n",
    "##### 例如关联规则尿布->葡萄酒=3/4,故得出结论所有包含“尿布”的记录中75%都适用\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f4f68c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "假设有4种商品，需要遍历数据15次,如下图所示\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1种</th>\n",
       "      <th>2种</th>\n",
       "      <th>3种</th>\n",
       "      <th>4种</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>012</td>\n",
       "      <td>0123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>013</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03</td>\n",
       "      <td>023</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>024</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>034</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>23</td>\n",
       "      <td>123</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>124</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>134</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>234</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1种    2种   3种    4种\n",
       "0     0    01  012  0123\n",
       "1     1    02  013  None\n",
       "2     2    03  023  None\n",
       "3     3    12  024  None\n",
       "4  None    13  034  None\n",
       "5  None    23  123  None\n",
       "6  None  None  124  None\n",
       "7  None  None  134  None\n",
       "8  None  None  234  None"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[i for i in range(4)]\n",
    "y=[i for i in range(4)]\n",
    "data=pd.DataFrame()\n",
    "# print([str(i)+str(j) for i in x for j in y if i!=j])\n",
    "data['1种']=[str(i) for i in x]+[None,None,None,None,None]\n",
    "data['2种']=['01', '02', '03', '12', '13', '23']+[None,None,None]\n",
    "data['3种']=['012','013','023','024','034','123','124','134','234']\n",
    "data['4种']=[''.join(list(map(str,x)))]+[None,None,None,None,None,None,None,None]\n",
    "print('假设有4种商品，需要遍历数据15次,如下图所示:')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e66104",
   "metadata": {},
   "source": [
    "##### 为了降低计算所需的时间，可以应用Apriori原理\n",
    "##### 该原理基于一种假设：如果该项集是频繁的，则其所有子集也是频繁的\n",
    "##### 如上图中{01}两种商品是一个频繁项集，则其子集{0}和{1}也是频繁的\n",
    "##### 如上图{23}两种商品组合不是频繁的，则{023}、{123}、{0123}也是不频繁的\n",
    "##### 下面就用代码来实现："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c806e71f",
   "metadata": {},
   "source": [
    "##### 伪代码如下：\n",
    "    对于数据集中的每条交易记录train:\n",
    "        对于每个候选集项can:\n",
    "            检查can是否属于train的子集\n",
    "            如果是子集:\n",
    "                增加can的计数器\n",
    "        对于每个候选集项:\n",
    "            如果其支持度不小于最小度量，则保留该项集\n",
    "    返回所有项集列表\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "374ebcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], [3], [4], [5]]\n",
      "商品种类为： [frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n",
      "单商品频繁项集为 [frozenset({3}), frozenset({2})]\n",
      "单商品支持度为： {frozenset({1}): 0.4, frozenset({2}): 1.0, frozenset({3}): 0.8, frozenset({4}): 0.4, frozenset({5}): 0.2}\n",
      "从上述数据可以根据设置最小支持度过滤掉部分数据，减少后续计算程度！\n"
     ]
    }
   ],
   "source": [
    "def loadDataSet():\n",
    "    return [[1,2,3],[1,2,3,4],[2,3],[2,3,4],[2,5]]\n",
    "\n",
    "# 创建一个不变集合（存放所有商品类别）\n",
    "def createC1(dataSet):\n",
    "    c1=[]\n",
    "    for trainsaction in dataSet:\n",
    "        for item in trainsaction:\n",
    "            if not [item] in c1:\n",
    "                c1.append([item])\n",
    "    c1.sort()\n",
    "    # 返回一个不变集合\n",
    "    # print(c1)\n",
    "    return list(map(frozenset,c1))\n",
    "\n",
    "# 输入参数分别为原始数据集、商品种类集合、最小支持度\n",
    "def scanD(D,ck,minSupport):\n",
    "    ssCnt={}\n",
    "    for tid in D:\n",
    "        for can in ck:\n",
    "            if can.issubset(tid):\n",
    "                if can not in ssCnt:\n",
    "                    ssCnt[can]=1\n",
    "                else:\n",
    "                    ssCnt[can]+=1\n",
    "                # 上述if-else等价于:\n",
    "                # ssCnt[can]=ssCnt.get(cant,0)+1\n",
    "    numItem=float(len(D))\n",
    "    retList=[]\n",
    "    supportData={}\n",
    "    for key in ssCnt:\n",
    "        # 计算所有项集的支持度\n",
    "        support=ssCnt[key]/numItem\n",
    "        # 根据支持度划分项集子集\n",
    "        if support>= minSupport:\n",
    "            retList.insert(0,key)\n",
    "        supportData[key]=support\n",
    "    return retList,supportData\n",
    "                \n",
    "   \n",
    "def test():\n",
    "    data=loadDataSet()\n",
    "    ck=createC1(data)\n",
    "    print('商品种类为：',ck)\n",
    "    retList,supportData=scanD(data,ck,0.5)\n",
    "    print('单商品频繁项集为',retList)\n",
    "    print('单商品支持度为：',supportData)\n",
    "    print('从上述数据可以根据设置最小支持度过滤掉部分数据，减少后续计算程度！')\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a4c80d",
   "metadata": {},
   "source": [
    "##### 整个Apriori算法伪代码如下：\n",
    "    当集合项中的个数大于0时:\n",
    "        构建一个k个项组成的候选项集的列表\n",
    "        检查数据以确认每个项集都是频繁的\n",
    "        保留频繁集项并构建k+1项组成的候选集的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62558867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], [3], [4], [5]]\n",
      "频繁项集为： [[frozenset({4}), frozenset({3}), frozenset({2}), frozenset({1})], [frozenset({1, 4}), frozenset({2, 4}), frozenset({3, 4}), frozenset({1, 2}), frozenset({1, 3}), frozenset({2, 3})], [frozenset({2, 3, 4}), frozenset({1, 3, 4}), frozenset({1, 2, 4}), frozenset({1, 2, 3})], [frozenset({1, 2, 3, 4})], []]\n",
      "频繁项集机：支持度为  {frozenset({1}): 0.8, frozenset({2}): 1.0, frozenset({3}): 0.8, frozenset({4}): 0.6, frozenset({5}): 0.2, frozenset({2, 3}): 0.8, frozenset({1, 3}): 0.8, frozenset({1, 2}): 0.8, frozenset({3, 4}): 0.6, frozenset({2, 4}): 0.6, frozenset({1, 4}): 0.6, frozenset({1, 2, 3}): 0.8, frozenset({1, 2, 4}): 0.6, frozenset({1, 3, 4}): 0.6, frozenset({2, 3, 4}): 0.6, frozenset({1, 2, 3, 4}): 0.6}\n"
     ]
    }
   ],
   "source": [
    "def loadDataSet():\n",
    "    return [[1,2,3],[1,2,3,4],[1,2,3,4],[2,5],[1,2,3,4]]\n",
    "\n",
    "# 该函数负责将Lk中的元素分解为不重复的子集所组成的列表\n",
    "def aprioriGen(Lk,k):\n",
    "    retList=[]\n",
    "    lenLk=len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1,lenLk):\n",
    "            L1=list(Lk[i])[:k-2]\n",
    "            L2=list(Lk[j])[:k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            # print(L1,L2)\n",
    "            # 如果两个列表相等就合并\n",
    "            if L1==L2:\n",
    "                retList.append(Lk[i]|Lk[j])\n",
    "    return retList\n",
    "\n",
    "\n",
    "def apriori(dataSet,minSupport=0.5):\n",
    "    C1=createC1(dataSet)\n",
    "    D=list(map(set,dataSet))\n",
    "    # print(\"将列表元素转换为集合：\",D)\n",
    "    L1,supportData=scanD(D,C1,minSupport)\n",
    "    L=[L1]\n",
    "    k=2\n",
    "    while(len(L[k-2])>0):\n",
    "        ck=aprioriGen(L[k-2],k)\n",
    "        Lk,supK=scanD(D,ck,minSupport)\n",
    "        supportData.update(supK)\n",
    "        if Lk!=None:\n",
    "            L.append(Lk)\n",
    "        k+=1\n",
    "    return L,supportData\n",
    "\n",
    "def test():\n",
    "    dataSet=loadDataSet()\n",
    "    L,supportData=apriori(dataSet,minSupport=0.5)\n",
    "    print('频繁项集为：',L)\n",
    "    print('频繁项集机：支持度为 ',supportData)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c13f4",
   "metadata": {},
   "source": [
    "##### 在计算可信度时可以注意到：如果一个项集不满足最低可信度，其子集也一定不满足\n",
    "##### 从频繁项集中挖掘关联规则：可以先从一个频繁项集开始，接着创建一个关联规则列表，右边只包含一个元素\n",
    "##### 然后对这些元素进行测试，接下来合并所有剩余规则创建一个新的规则列表，列表右边包含两个元素（该方法为分级法）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d923e329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在当前数据集上生成一个置信度大于0.7，且其项集支持度大于0.5的关联规则：\n",
      "[[1], [2], [3], [4], [5]]\n",
      "frozenset({4}) --> frozenset({1}) conf: 1.0\n",
      "frozenset({1}) --> frozenset({4}) conf: 0.7499999999999999\n",
      "frozenset({4}) --> frozenset({2}) conf: 1.0\n",
      "frozenset({4}) --> frozenset({3}) conf: 1.0\n",
      "frozenset({3}) --> frozenset({4}) conf: 0.7499999999999999\n",
      "frozenset({2}) --> frozenset({1}) conf: 0.8\n",
      "frozenset({1}) --> frozenset({2}) conf: 1.0\n",
      "frozenset({3}) --> frozenset({1}) conf: 1.0\n",
      "frozenset({1}) --> frozenset({3}) conf: 1.0\n",
      "frozenset({3}) --> frozenset({2}) conf: 1.0\n",
      "frozenset({2}) --> frozenset({3}) conf: 0.8\n",
      "frozenset({4}) --> frozenset({2, 3}) conf: 1.0\n",
      "frozenset({3}) --> frozenset({2, 4}) conf: 0.7499999999999999\n",
      "frozenset({4}) --> frozenset({1, 3}) conf: 1.0\n",
      "frozenset({3}) --> frozenset({1, 4}) conf: 0.7499999999999999\n",
      "frozenset({1}) --> frozenset({3, 4}) conf: 0.7499999999999999\n",
      "frozenset({4}) --> frozenset({1, 2}) conf: 1.0\n",
      "frozenset({1}) --> frozenset({2, 4}) conf: 0.7499999999999999\n",
      "frozenset({3}) --> frozenset({1, 2}) conf: 1.0\n",
      "frozenset({2}) --> frozenset({1, 3}) conf: 0.8\n",
      "frozenset({1}) --> frozenset({2, 3}) conf: 1.0\n",
      "frozenset({3, 4}) --> frozenset({1, 2}) conf: 1.0\n",
      "frozenset({2, 4}) --> frozenset({1, 3}) conf: 1.0\n",
      "frozenset({2, 3}) --> frozenset({1, 4}) conf: 0.7499999999999999\n",
      "frozenset({1, 4}) --> frozenset({2, 3}) conf: 1.0\n",
      "frozenset({1, 3}) --> frozenset({2, 4}) conf: 0.7499999999999999\n",
      "frozenset({1, 2}) --> frozenset({3, 4}) conf: 0.7499999999999999\n",
      "frozenset({4}) --> frozenset({1, 2, 3}) conf: 1.0\n",
      "frozenset({3}) --> frozenset({1, 2, 4}) conf: 0.7499999999999999\n",
      "frozenset({1}) --> frozenset({2, 3, 4}) conf: 0.7499999999999999\n",
      "关联规则为： [(frozenset({4}), frozenset({1}), 1.0), (frozenset({1}), frozenset({4}), 0.7499999999999999), (frozenset({4}), frozenset({2}), 1.0), (frozenset({4}), frozenset({3}), 1.0), (frozenset({3}), frozenset({4}), 0.7499999999999999), (frozenset({2}), frozenset({1}), 0.8), (frozenset({1}), frozenset({2}), 1.0), (frozenset({3}), frozenset({1}), 1.0), (frozenset({1}), frozenset({3}), 1.0), (frozenset({3}), frozenset({2}), 1.0), (frozenset({2}), frozenset({3}), 0.8), (frozenset({4}), frozenset({2, 3}), 1.0), (frozenset({3}), frozenset({2, 4}), 0.7499999999999999), (frozenset({4}), frozenset({1, 3}), 1.0), (frozenset({3}), frozenset({1, 4}), 0.7499999999999999), (frozenset({1}), frozenset({3, 4}), 0.7499999999999999), (frozenset({4}), frozenset({1, 2}), 1.0), (frozenset({1}), frozenset({2, 4}), 0.7499999999999999), (frozenset({3}), frozenset({1, 2}), 1.0), (frozenset({2}), frozenset({1, 3}), 0.8), (frozenset({1}), frozenset({2, 3}), 1.0), (frozenset({3, 4}), frozenset({1, 2}), 1.0), (frozenset({2, 4}), frozenset({1, 3}), 1.0), (frozenset({2, 3}), frozenset({1, 4}), 0.7499999999999999), (frozenset({1, 4}), frozenset({2, 3}), 1.0), (frozenset({1, 3}), frozenset({2, 4}), 0.7499999999999999), (frozenset({1, 2}), frozenset({3, 4}), 0.7499999999999999), (frozenset({4}), frozenset({1, 2, 3}), 1.0), (frozenset({3}), frozenset({1, 2, 4}), 0.7499999999999999), (frozenset({1}), frozenset({2, 3, 4}), 0.7499999999999999)]\n"
     ]
    }
   ],
   "source": [
    "def generateRules(L, supportData, minConf=0.7):  #supportData is a dict coming from scanD\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):#only get the sets with two or more items\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            # 只获取有两个或更多元素的集合\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList         \n",
    "\n",
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    prunedH = [] #create new list to return\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] #calc confidence\n",
    "        if conf >= minConf: \n",
    "            print(freqSet-conseq,'-->',conseq,'conf:',conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)): #try further merging\n",
    "        Hmp1 = aprioriGen(H, m+1)#create Hm+1 new candidates\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        if (len(Hmp1) > 1):    #need at least two sets to merge\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)\n",
    "\n",
    "def test():\n",
    "    data=loadDataSet()\n",
    "    print('在当前数据集上生成一个置信度大于0.7，且其项集支持度大于0.5的关联规则：')\n",
    "    L,supportData=apriori(data,minSupport=0.5)\n",
    "    rules=generateRules(L,supportData,minConf=0.7)\n",
    "    print('关联规则为：',rules)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0eff2",
   "metadata": {},
   "source": [
    "##### 案例：发现毒蘑菇的相似特征\n",
    "##### 数据集介绍：mushroom.dat\n",
    "##### 第一列表示是否有毒（1：无毒；2：有毒）\n",
    "##### 第二列为蘑菇伞形状，有六种可能值\n",
    "##### 一共有23种特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93ea4bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1'], ['10'], ['100'], ['101'], ['102'], ['103'], ['104'], ['105'], ['106'], ['107'], ['108'], ['109'], ['11'], ['110'], ['111'], ['112'], ['113'], ['114'], ['115'], ['116'], ['117'], ['118'], ['119'], ['12'], ['13'], ['14'], ['15'], ['16'], ['17'], ['18'], ['19'], ['2'], ['20'], ['21'], ['22'], ['23'], ['24'], ['25'], ['26'], ['27'], ['28'], ['29'], ['3'], ['30'], ['31'], ['32'], ['33'], ['34'], ['35'], ['36'], ['37'], ['38'], ['39'], ['4'], ['40'], ['41'], ['42'], ['43'], ['44'], ['45'], ['46'], ['47'], ['48'], ['49'], ['5'], ['50'], ['51'], ['52'], ['53'], ['54'], ['55'], ['56'], ['57'], ['58'], ['59'], ['6'], ['60'], ['61'], ['62'], ['63'], ['64'], ['65'], ['66'], ['67'], ['68'], ['69'], ['7'], ['70'], ['71'], ['72'], ['73'], ['74'], ['75'], ['76'], ['77'], ['78'], ['79'], ['8'], ['80'], ['81'], ['82'], ['83'], ['84'], ['85'], ['86'], ['87'], ['88'], ['89'], ['9'], ['90'], ['91'], ['92'], ['93'], ['94'], ['95'], ['96'], ['97'], ['98'], ['99']]\n",
      "所有结果包含2的频繁项集为：\n",
      "frozenset({'2', '28'})\n",
      "frozenset({'2', '53'})\n",
      "frozenset({'2', '23'})\n",
      "frozenset({'2', '34'})\n",
      "frozenset({'36', '2'})\n",
      "frozenset({'59', '2'})\n",
      "frozenset({'63', '2'})\n",
      "frozenset({'2', '67'})\n",
      "frozenset({'2', '76'})\n",
      "frozenset({'2', '85'})\n",
      "frozenset({'2', '86'})\n",
      "frozenset({'2', '90'})\n",
      "frozenset({'93', '2'})\n",
      "frozenset({'39', '2'})\n"
     ]
    }
   ],
   "source": [
    "def loadDataSet(filename):\n",
    "    mushData=[]\n",
    "    with open(filename) as f:\n",
    "        data=f.readlines()\n",
    "    for line in data:\n",
    "        mushData.append(line.split())\n",
    "    return mushData\n",
    "\n",
    "def test():\n",
    "    mushData=loadDataSet(r'data/mushroom.dat')\n",
    "    L,supportData=apriori(mushData,minSupport=0.3)\n",
    "    print('所有结果包含2的频繁项集为：')\n",
    "    for i in L[1]:\n",
    "        if i.intersection('2'):\n",
    "            print(i)\n",
    "        \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5eab9",
   "metadata": {},
   "source": [
    "### 本章小结：\n",
    "##### 关联分析是用于发现大数据集中元素间有趣关系的一个工具集\n",
    "##### 可以适用频繁项集来对这种关系进行量化，但直接计算组合会耗费大量时间，可以采用apriori方法\n",
    "##### 可以适用支持度和可信度来生成一条关联规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33afdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
