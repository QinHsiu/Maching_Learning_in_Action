{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ea9f01",
   "metadata": {},
   "source": [
    "# 元算法：将几种算法进行组合的一种方式\n",
    "# AdaBoost集成学习算法\n",
    "### 优点：泛化错误率低，易编码，可以应用在大部分编码器上，无参数调整\n",
    "### 缺点：对离群点敏感\n",
    "### 适用数据类型：数值型和标称型\n",
    "\n",
    "##### bagging：基于数据随机重抽样的分类器构建方法\n",
    "##### boosting aggression:自举汇聚法，从原始数据中选择S次得到S个新数据集，新数据集和原始数据集大小相等\n",
    "##### 更多资料参看：[资料](https://www.stat.berkeley.edu/~breiman/RandomForests/)\n",
    "##### boosting是一种与bagging类似的技术，两者所使用的分类器类型一直，只是分类器训练方式不同\n",
    "##### boosting训练器是通过观察已有的分类器错分的那些数据来获取新的分类器，boosting分类的结果是基于所有分类器的加权求和结果\n",
    "##### bagging训练器是通过串行训练而获得，每个新分类器都是根据已经训练好的分类器的性能来进行训练，bagging的权重相等\n",
    "\n",
    "##### AdaBoost一般流程\n",
    "##### 搜集数据\n",
    "##### 准备数据：依赖于所使用的弱分类器类型\n",
    "##### 分析数据\n",
    "##### 训练算法：AdaBoost大部分开销用在训练上，分类器将多次在同一数据集上训练\n",
    "##### 测试算法：计算分类错误率\n",
    "##### 使用算法：同SVM一样，AdaBoost用于二分类，要用于多分类需要进行修改\n",
    "\n",
    "##### 训练算法：机遇错误提升分类器的性能\n",
    "##### “弱”分类器中“弱”是指分类器的性能比随机猜测要略好\n",
    "##### 具体步骤：首先在训练集上训练一个弱分类器并计算错误率，然后在同一数据集上再次训练弱分类器\n",
    "##### 在第二次训练中调整每个样本的权重，AdaBoost为每个分类器都定义了一个权重值alpha，alpha=1/2*(ln((1-e)/e))，其中e表示错误率\n",
    "##### 计算出alpha后对权重进行更新，如果分类器分类正确就降低其权重，分类错误就提升其权重\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32fcad7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEFCAYAAAARwQdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAASsUlEQVR4nO3df5BdZ33f8fdHNgZ3pRBhb+XxYEVVLRpcCDjZDJgRRThojD2dTnA7s9OYpsYeROi4CXhoAxXGTsO0lAFSwEBRfhCTtK5MJmRIYowBWalcA9PV0B+QNEgQXOofQaa2fmUmA9K3f5yj0c6yP+5K9+6PZ9+vGc3ePee5z/M9d7Wffe5z7r0nVYUkaXVbt9wFSJLOn2EuSQ0wzCWpAYa5JDXAMJekBhjmktQAw3wNSnJXkhNJnknyUJIXnWd/H0wyOar2i6zl/UkeS/KnSV42ijEWUcvvJ3kyyakkR/rbz16CcfcneTrJ95L8TpLnjnpMLT/DfO26GxgH9gH3n0/IVNUvVdXeUbUfVJLXAVcBm4FfBn592r4tSW4e9pjzqaobq+oy4DvAK6vqsqr663PpK8lLk/zsIu7yj4GtwI8y7XEYYv9aYQzzNayqvl9Vvwr8AHj1ctczBC8CvllVp4DPAr8xbd8W4OZlqGlYXgr87GLuUFVHgduA1yVZP+z+tbIY5gL4H8CPAyR5Q5JvJPlOkjeeaZDkXyT5P/3210+/c5LfnjnrTfIrSR5P8kSSfzZA+zP9/3mS6/ttdyX5tSQP9EsGH1zgOB4EbknybmB9VX2o7+cA8PvAK/qljl+f1v9d02r4dj+DrySfTPIXSd6X5Kkk1/bLF7/bPwYHk7xgwUd2FkkuTPLvkzzaLwe9vN9+cZJP9zV+I8n2M3UBHwQm+33vGnSsqnoUOAFcmeRv9P0/keRrSa6er/+52mtlMswF3S/7+n7t/Hbgp+lmancl2ZRkJ/BPgJ8AXgl8bL6ZXpLn0S1zvJButvwz8w2e5DXAPwVeArwO+ESSTf3uW4A7+rHf1Pc9q6r6CnAdsBM4nOS6fvsrgRuBR/qljjfO1cc0HwK+BzwJ/Dawvd/+HODH+m0fGqCf2bwR2Ei3DPJm4OP99uuBvwlcDuwCXtPXvwX4JWBvX/+/XuR4J4D1dI/NE33/7wbesUD/s7bXynThchegFWGM7hf+1XQB8+f99ouBvwO8FviPVfUM8AywYYH+jgKH6GZ7D9AF9XyuB363qp4Gnk7yFbo/GgB/WFX/DSDJXwI/Avy/uTqqqgPAy5L8AnBfki19v4PItNsH6R6Tg8CrODvx+WRVnU5yL/CrA/Y702uAa4HH+u8vTnIh3TOkrcC/oTuXsdjQnssYcKKqHk7yV8D76B7z7853p6r69GLaa3k5MxfAi4Gv04XZJ/vZ2WXA84Evz2yc5B8luXyuzvo1658Gfo8uCL+a5KIFaqg5bn9zju0/JMknkvxMX8N/AP4v8LcXGPfMfS8EzjwboM5+At3MMc8E/jrg9CB9zzYc8AvTHue/BZyqqm/SPQP5GvA24BPn2P/ZgZLn083KDyXZDfxL4E+AfzXAfRfVXsvLMF/D+rXbt9OFy3662eD1SS5LsoFupngV8Dng55I8tw/xu5knyPq15C/2/34ZuAy4ZJ5SPgvclORHk/w48DLgQL9vMR/r+QTdmvkFfQ2X0j1DAHgKeH6/b2OSC4BjwBX9/l3AIK/ouTnJOrpXizyyiNqm+wLw80kuSvITwP8G1iV5A/BO4D8B7wFePu0+T9Et75Dk0kEGSfIjdEtB91bVSeAa4FN0P8/XzWg+W//ztdcKY5ivXbcBR+hmztf1r2z5Gt3SwZeAPwU+UlX/vaoepAuY/wU8DLy1qp6cq+Oq+gZdGP8F8A3g7qp6Yp72XwB+B/ifwGeAW6rqL8/hmN5DF8iPAX8I3Nq/ooP+2L7Q7/sacBHwn4GJJA/SvZzx0QHGeBr4Nt05hLecQ40Ae4Bv0T0+9wE/1z+b+T26WfqTwG/RBfsZnwOO9ktNXxhgjHvpntV8l25dHuCjwLvofrbPAFv7P2pz9T9fe60w8fPMpcEk2Q/cVVX7l7kU6Yc4M5ekBjgzl6QGODOXpAYY5pLUgGV509Cll15aW7ZsWY6hJWnVOnjw4FNVNT7bvmUJ8y1btjA1NbUcQ0vSqpVkzpfPuswiSQ0wzCWpAYa5JDXAMJekBqyej8A9fhz27oVDh2DbNpichA0LfRKrJK0NqyPMH34YbrgBTp+GkydhbAxuvx3uvx+2b1/4/pLUuJW/zHL8eBfkx493QQ7d1zPbT5xY3vokaQVY+WG+d283I5/N6dPdfkla41Z+mB86dHZGPtPJk3D48NLWI0kr0MoP823bujXy2YyNwZVXLm09krQCrfwwn5yEdXOUuW5dt1+S1riVH+YbNnSvWtmw4ewMfWzs7Pb165e3PklaAVbHSxO3b4fHH+9Odh4+3C2tTE4a5JLUWx1hDl1w33rrclchSSvSyl9mkSQtyDCXpAYY5pLUAMNckhpgmEtSAwxzSWqAYS5JDTDMJakBhrkkNcAwl6QGLBjmSZ6b5LNJPp/k00kumqPdbyZ5JMk7h1+mJGk+g8zMbwI+UFU7gSeB185skORG4IKqegVweZJtwy1TkjSfBT9oq6o+Ou3bceC7szTbAdzX394HbAcOTW+QZBewC2Dz5s3nUKokaS4Dr5knuQbYWFVfnmX3GPBYf/sYsGlmg6raU1UTVTUxPj5+TsVKkmY30EfgJnke8GHgH87R5ARwcX97PZ5YlaQlNcgJ0IvollDeUVWPztHsIN3SCsBLgG8PpTpJ0kAGmZnfCvwUsDvJbuAh4FlVNf1VK38AHEhyOXA98PJhFypJmtsgJ0A/BnxsgTbHkuwAdgLvraqjQ6lOkjSQoV02rqqe5uwrWiRJS8gTlZLUAMNckhpgmEtSAwxzSWqAYS5JDTDMJakBhrkkNcAwl6QGGOaS1ADDXJIaYJhLUgMMc0lqgGEuSQ0wzCWpAYa5JDXAMJekBhjmktQAw1ySGmCYS1IDDHNJaoBhLkkNMMwlqQGGuSQ1wDCXpAYY5pLUAMNckhowUJgn2ZTkwDz7tyb5YpIvJbljeOVJkgaxYJgn2QjcA4zN0+w24I6quga4Lsn4kOqTJA1gkJn5KWASODZPm+8BL0yyCbgIeOb8S5MkDerChRpU1TGAJPM1ewD4RWAr8BDwg5kNkuwCdgFs3rz5HEqVJM1lWCdA7wRurqrdwMXAzpkNqmpPVU1U1cT4uKswkjRMwwrzy4ErkjwH+EmghtSvJGkAiw7zJNcmuW3G5juB/cAR4DvAvvMvTZI0qAXXzM+oqh39133MCOuq+mPgj4damSRpYL5pSJIaYJhLUgMMc0lqgGEuSQ0wzCWpAYa5JDXAMJekBhjmktQAw1ySGmCYS1IDDHNJaoBhLkkNMMwlqQGGuSQ1wDCXpAYY5pLUAMNckhpgmEtSAwxzSWqAYS5JDTDMJakBhrkkNcAwl6QGGOaS1ADDXJIaYJhLUgMMc0lqgGEuSQ0YKMyTbEpyYIB2n0ly9fmXJUlajAXDPMlG4B5gbIF2NwHfqqqvDqk2SdKABpmZnwImgWNzNUjyPOD9wNNJXj2k2iRJA1owzKvqWFUdXaDZW4FPAR8Hfj7JP5jZIMmuJFNJpo4cOXJu1UqSZjWsE6BXAx+pqieB+4AdMxtU1Z6qmqiqifHx8SENK0mC4YX5YWBrf3sCeHRI/UqSBrDoME9ybZLbZmx+L3Bbkv8K/D3gt4ZRnCRpMBcO2rCqdvRf9wH7Zux7HLhhqJVJkgbmm4YkqQGGuSQ1wDCXpAYY5pLUAMNckhpgmEtSAwxzSWqAYS5JDTDMJakBhrkkNcAwl6QGGOaS1ADDXJIaYJhLUgMMc0lqgGEuSQ0wzCWpAYa5JDXAMJekBhjmktQAw1ySGmCYS1IDDHNJaoBhLkkNMMwlqQGGuSQ1wDCXpAYY5pLUgIHCPMmmJAcGaPeiJA+ef1mSpMVYMMyTbATuAcYWaBfgA8BFwylNkjSoQWbmp4BJ4NgC7d4APHTeFUmSFm3BMK+qY1V1dL42SS4BXg+8b542u5JMJZk6cuTI4iuVJM1pWCdA3wO8o6q+P1eDqtpTVRNVNTE+Pj6kYSVJABcOqZ9XAdu6ZXNemuTdVfXOIfUtSVrAosM8ybXAVVV195ltVfWCafv3G+SStLQGDvOq2tF/3QfsW6idJGnp+KYhSWqAYS5JDTDMJakBhrkkNcAwl6QGGOaS1ADDXJIaYJhLUgMMc0lqgGEuSQ0wzCWpAYa5JDXAMJekBhjmktQAw1ySGmCYS1IDDHNJaoBhLkkNMMwlqQGGuSQ1wDCXpAYY5pLUAMNckhpgmEtSAwxzSWqAYS5JDTDMJakBhrkkNWCgME+yKcmBefZvTrI/yb4ke5JkeCVKkhayYJgn2QjcA4zN0+xNwJur6lrgCuDFwylPkjSIQWbmp4BJ4NhcDapqd1X9Wf/tJcBTQ6hNkjSgBcO8qo5V1dFBOksyCXy9qh6fZd+uJFNJpo4cOXIOpUqS5jK0E6BJtgJvA94y2/6q2lNVE1U1MT4+PqxhJUkMKcz7dfV7gVsGncVLkoZn0WGe5Nokt83Y/HZgM/Dh/lUtrxpKdZKkgaSqlnzQiYmJmpqaWvJxJWk1S3KwqiZm2+ebhiSpAYa5JDXAMJekBhjmktQAw1ySGmCYS1IDDHNJaoBhLkkNMMwlqQEXLncBkrQmHD8Oe/fCoUOwbRtMTsKGDUPr3jCXpFF7+GG44QY4fRpOnoSxMbj9drj/fti+fShDuMwiSaN0/HgX5MePd0EO3dcz20+cGMowhrkkjdLevd2MfDanT3f7h8Awl6RROnTo7Ix8ppMn4fDhoQxjmEvSKG3b1q2Rz2ZsDK68cijDGOaSNEqTk7Bujqhdt67bPwSGuSSN0oYN3atWNmw4O0MfGzu7ff36oQzjSxMladS2b4fHH+9Odh4+3C2tTE4OLcjBMJekpbF+Pdx668i6d5lFkhpgmEtSAwxzSWqAYS5JDTDMJakBhrkkNcAwl6QGrOjXmf/dOx/g5F+fWrDd2LMv4Ou/8tolqKhtPt7S6rWiw3yQYFlMO83Px1saIa80JEmr3Eq50lCSTUkOzLP/WUn+KMkjSW4ZSmWS1IKVcqWhJBuBe4A5PpAXgH8OTFXVK4C/n2R4zx0kaTVbQVcaOgVMAsfmabMDuK+//QgwMbNBkl1JppJMHTlyZLF1StLqtFKuNFRVx6rq6ALNxoDH+tvHgE2z9LOnqiaqamJ8fHzxlUrSarTKrjR0Ari4v71+iP1K0uq2yq40dBA4c0r2JcC3h9SvJK1uK/VKQ0muBa6qqrunbb4HuD/JK4GrgK8MpTpJasFKutJQVe3ov+4D9s3Y92iSnXSz83dV1VDeVTL27AsGfkeizp+PtzRCI77SUKpqZJ3PZWJioqamppZ8XElazZIcrKoferUgeKJSkppgmEtSAwxzSWrAsqyZJzkCPHqOd78UeGqI5awGHvPa4DGvDedzzD9WVbO+63JZwvx8JJma6wRAqzzmtcFjXhtGdcwus0hSAwxzSWrAagzzPctdwDLwmNcGj3ltGMkxr7o1c0nSD1uNM3NJ0gyGuSQ1YEWH+Vq89ugAx7w5yf4k+5LsSZKlrG8UFjrmae1elOTBpahplBZxvJ9JcvVS1DRqA/y/3prki0m+lOSOpaxtFJI8N8lnk3w+yaeTXDRHu9/s8+ud5zvmig3ztXjt0QGP+U3Am6vqWuAK4MVLUduoDHjM9H+0PgDM+kuxWizieG8CvlVVX12SwkZowGO+Dbijqq4Brkuy2i9HdhPwgaraCTwJvHZmgyQ3Ahf0+XV5km3nM+CKDXOGdO3RVWbBY66q3VX1Z/23l7D63z03yM8Z4A3AQ6MvZ+QWPN4kzwPeDzyd5NVLVdgIDfIz/h7wwiSb6P5gP7MEdY1MVX20qj7ffzsOfHeWZjs4m1/7OHuBn3Oy6ItTLJWqOgawwCrCgtceXU0GPGb6NpPA16vq8VHXNUqDHHOSS4DXA9f1/1atAX/GbwU+BXwc+LdJNlTVZ5agvJEY8JgfAH4R2Er3R/sHo69s9JJcA2ysqi/Psntmfp3XxUBX8sx8EGvy2qNJtgJvA96yzKUslfcA76iq7y93IUvkauAjVfUk3cxtx/KWsyTuBG6uqt10v9M7l7me89Y/w/owMNf5vKHm12oPvzV37dF+/fFe4JaqOrrc9SyRVwH/Lsl+4KVJ3r3M9YzaYboZKnRLh+f6oXSryeXAFUmeA/wksKrfANOf8LyPbhIy189vqPm1YpdZZlqL1x6d45jfDmwGPtw/bb2zqv5kOeobhdmOuapeMG3//qo67zP/K8UcP+P3Ar+RZDfwV8CNy1LciMxxzHcC++nWl/+IGZemXIVuBX4K2N3/HB8CnjXj/+4fAAeSXA5cD7z8fAZc9e8A7R+I7cDn1tBMVVID+mfaO4H/0i+rnXtfqz3MJUmrf81ckoRhLklNMMwlqQGGuSQ1wDCXpAb8fzqYIuNznc2mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from numpy import* \n",
    "##### 基于单层决策树构建弱分类器\n",
    "def loadSimpData():\n",
    "    datMat = matrix([[ 1. ,  2.1],\n",
    "        [ 2. ,  1.1],\n",
    "        [ 1.3,  1. ],\n",
    "        [ 1. ,  1. ],\n",
    "        [ 2. ,  1. ]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat,classLabels\n",
    "\n",
    "# 查看数据分布\n",
    "import matplotlib.pyplot as plt\n",
    "def showP(datMat,classLbels):\n",
    "    xcord0 = []\n",
    "    ycord0 = []\n",
    "    xcord1 = []\n",
    "    ycord1 = []\n",
    "    markers =[]\n",
    "    colors =[]\n",
    "    for i in range(len(classLabels)):\n",
    "        if classLabels[i]==1.0:\n",
    "            xcord1.append(datMat[i,0]), ycord1.append(datMat[i,1])\n",
    "        else:\n",
    "            xcord0.append(datMat[i,0]), ycord0.append(datMat[i,1])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)       \n",
    "    ax.scatter(xcord0,ycord0, marker='s', s=90)\n",
    "    plt.rcParams['font.sans-serif']=['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    ax.scatter(xcord1,ycord1, marker='o', s=50, c='red')\n",
    "    plt.title('Decision Stump Test Data')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "dataMat,classLabels=loadSimpData()\n",
    "showP(dataMat,classLabels)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d074ff",
   "metadata": {},
   "source": [
    "# 建立单层决策树\n",
    "### 伪代码如下：\n",
    "### 用+无穷初始化最下错误率\n",
    "### 对数据集中的每一个特征（第一层循环）：\n",
    "     对每个步长（第二层循环）：\n",
    "         对每个不等号（第三层循环）：\n",
    "             建立一棵单层决策树并利用加权数据集对它进行预测\n",
    "             如果错误率低于最小错误率，则将当前单层决策树设为最佳单层决策树\n",
    "### 返回最佳决策树\n",
    "\n",
    "### 该函数通过阈值比较对数据进行分类，所有在阈值一边的会分类到类别-1，而在另外一边就分类到+1\n",
    "### 该函数通过数据过滤来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd59956f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 1.3, 'ineq': 'lt'},\n",
       " matrix([[0.2]]),\n",
       " array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):#just classify the data\n",
    "    # 将返回数组所有值设为1，然后将所有满足不等式要求的元素设置为-1\n",
    "    retArray = ones((shape(dataMatrix)[0],1))\n",
    "    # 基于输入参数返回分类预测结果\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray\n",
    "    \n",
    "\n",
    "def buildStump(dataArr,classLabels,D):\n",
    "    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n",
    "    m,n = shape(dataMatrix)\n",
    "    # bestStump字典用于存放给定权重向量D时所得到的最佳决策树的相关信息\n",
    "    # numSteps用于在特征所有可能值上进行遍历\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n",
    "    minError = inf #init error sum, to +infinity\n",
    "    # 遍历stumpClassify()函数所有可能的输入值，并找到最佳单层决策树\n",
    "    for i in range(n):#loop over all dimensions\n",
    "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();\n",
    "        # 步长\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps\n",
    "        for j in range(-1,int(numSteps)+1):#loop over all range in current dimension\n",
    "            # 在大于与小于之间切换不等式\n",
    "            for inequal in ['lt', 'gt']: #go over less than and greater than\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                # 分类预测结果\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)#call stump classify with i, j, lessThan\n",
    "                # 用于记录分类错误的相应位置\n",
    "                errArr = mat(ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                # 通过初始权重与错误矩阵相乘得到错误值\n",
    "                weightedError = D.T*errArr  #calc total error multiplied by D\n",
    "                # print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
    "                # 将其与最小错误率进行比较\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    # 返回字典、错误率和预测结果\n",
    "    return bestStump,minError,bestClasEst\n",
    "\n",
    "D=mat(ones((5,1))/5)\n",
    "buildStump(dataMat,classLabels,D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b6686",
   "metadata": {},
   "source": [
    "# 完整AdaBoost实现\n",
    "### 伪代码如下：\n",
    "### 对于每次迭代：\n",
    "     利用buildStump()函数找到最佳决策单层树\n",
    "     将最佳决策单层树加入到单层决策树数组\n",
    "     计算alpha\n",
    "     计算新的权重向量D\n",
    "     跟新累计类别估计值\n",
    "     如果错误率在要求范围内（含0）推出循环\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8816c783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453},\n",
       " {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.8958797346140273}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40):\n",
    "    weakClassArr = []\n",
    "    m = shape(dataArr)[0]\n",
    "    D = mat(ones((m,1))/m)   #init D to all equal\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    # 设置最大迭代次数\n",
    "    for i in range(numIt):\n",
    "        bestStump,error,classEst = buildStump(dataArr,classLabels,D)#build Stump\n",
    "        #print(\"D:\",D.T)\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))#calc alpha, throw in max(error,eps) to account for error=0\n",
    "        # 该字典包含了分类所需要的所有信息\n",
    "        bestStump['alpha'] = alpha  \n",
    "        weakClassArr.append(bestStump)                  #store Stump Params in Array\n",
    "        #print(\"classEst: \",classEst.T)\n",
    "        expon = multiply(-1*alpha*mat(classLabels).T,classEst) #exponent for D calc, getting messy\n",
    "        D = multiply(D,exp(expon))                              #Calc New D for next iteration\n",
    "        D = D/D.sum()\n",
    "        #calc training error of all classifiers, if this is 0 quit for loop early (use break)\n",
    "        aggClassEst += alpha*classEst\n",
    "        #print(\"aggClassEst: \",aggClassEst.T)\n",
    "        # 错误率累加计算\n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        # print(\"total error: \",errorRate)\n",
    "        # 如果错误率为0直接推出循环\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "    return weakClassArr\n",
    "\n",
    "\n",
    "adaBoostTrainDS(dataMat,classLabels,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d8897e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试算法：基于AdaBoost的分类\n",
    "def adaClassify(datToClass,classifierArr):\n",
    "    dataMatrix = mat(datToClass)#do stuff similar to last aggClassEst in adaBoostTrainDS\n",
    "    m = shape(dataMatrix)[0]\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'],\\\n",
    "                                 classifierArr[i]['thresh'],\\\n",
    "                                 classifierArr[i]['ineq'])#call stump classify\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        # print(aggClassEst)\n",
    "    return sign(aggClassEst)\n",
    "\n",
    "classifierArr=adaBoostTrainDS(dataMat,classLabels,30)\n",
    "# print(adaClassify([[5,5],[0,0]],classifierArr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d744531",
   "metadata": {},
   "source": [
    "# 在一个难数据集上应用AdaBoost\n",
    "### 搜集数据：从文本读取\n",
    "### 准备数据：确保类别标签属于{-1,1}\n",
    "### 分析数据：检查数据\n",
    "### 训练算法：利用训练器训练出分类器\n",
    "### 测试算法：对AdaBosst和逻辑回归的结果进行比较\n",
    "### 使用算法：观察错误率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a589af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类器数目    训练错误率    测试错误率\n",
      "1             0.28             0.27\n",
      "10             0.23             0.24\n",
      "50             0.19             0.21\n",
      "100             0.19             0.22\n",
      "500             0.16             0.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def loadDataSet(fileName):      #general function to parse tab -delimited floats\n",
    "    numFeat = len(open(fileName).readline().split('\\t')) #get number of fields \n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr =[]\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat,labelMat\n",
    "\n",
    "dataMat,classLabels=loadDataSet(r'horseColicTraining2.txt')\n",
    "# print(shape(dataMat))\n",
    "testMat,testLabels=loadDataSet(r'horseColicTest2.txt')\n",
    "# print(shape(testMat))\n",
    "print(\"分类器数目    训练错误率    测试错误率\")\n",
    "for i in [1,10,50,100,500]:\n",
    "    # 获取分类器\n",
    "    classifierArr=adaBoostTrainDS(dataMat,classLabels,i)\n",
    "    # 使用训练好的分类器进行训练\n",
    "    trainR=adaClassify(dataMat,classifierArr)\n",
    "    prediction=adaClassify(testMat,classifierArr)\n",
    "    # 预测错误结果\n",
    "    errorArr=mat(ones((67,1)))\n",
    "    errorArr[prediction!=mat(testLabels).T].sum()\n",
    "    # 训练错误结果\n",
    "    errorArr1=mat(ones((299,1)))\n",
    "    errorArr1[trainR!=mat(classLabels).T].sum()\n",
    "    a=i\n",
    "    b=errorArr1[trainR!=mat(classLabels).T].sum()/299\n",
    "    c=errorArr[prediction!=mat(testLabels).T].sum()/67\n",
    "    print(\"%d             %.2f             %.2f\"%(a,b,c),end=\"\\n\")\n",
    "\n",
    "### 从错误率中可以看出训练错误率一直在下降，但是测试错误率先下降后上升，这就是过拟合现象\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2faf9c3",
   "metadata": {},
   "source": [
    "# 非均衡分类问题：在大多数情况下不同类别的分类代价不同\n",
    "### 分类度量指标：正确率、召回率、ROC曲线\n",
    "### 可以通过混淆矩阵观察分类中的错误情况\n",
    "### 当某个类别重要性高于其他类别时，可以利用上述指标来进行抉择\n",
    "### ROC曲线不但可以用于比较分类，还可以基于成本效益分析来做出决策\n",
    "### 对于不同ROC曲线的一个比较指标就是曲线下面积，AUC，其代表分类器的平均性能值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "813ce991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Area Under the Curve is:  0.8582969635063604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40):\n",
    "    weakClassArr = []\n",
    "    m = shape(dataArr)[0]\n",
    "    D = mat(ones((m,1))/m)   #init D to all equal\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    # 设置最大迭代次数\n",
    "    for i in range(numIt):\n",
    "        bestStump,error,classEst = buildStump(dataArr,classLabels,D)#build Stump\n",
    "        #print(\"D:\",D.T)\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))#calc alpha, throw in max(error,eps) to account for error=0\n",
    "        # 该字典包含了分类所需要的所有信息\n",
    "        bestStump['alpha'] = alpha  \n",
    "        weakClassArr.append(bestStump)                  #store Stump Params in Array\n",
    "        #print(\"classEst: \",classEst.T)\n",
    "        expon = multiply(-1*alpha*mat(classLabels).T,classEst) #exponent for D calc, getting messy\n",
    "        D = multiply(D,exp(expon))                              #Calc New D for next iteration\n",
    "        D = D/D.sum()\n",
    "        #calc training error of all classifiers, if this is 0 quit for loop early (use break)\n",
    "        aggClassEst += alpha*classEst\n",
    "        #print(\"aggClassEst: \",aggClassEst.T)\n",
    "        # 错误率累加计算\n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        # print(\"total error: \",errorRate)\n",
    "        # 如果错误率为0直接推出循环\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "    return weakClassArr,aggClassEst\n",
    "\n",
    "dataArr,labelArr=loadDataSet(r'horseColicTraining2.txt')\n",
    "classifierArr,aggClassEst=adaBoostTrainDS(dataMat,classLabels,10)\n",
    "    \n",
    "\n",
    "# 两个参数分别为分类器预测强度、类标签\n",
    "def plotROC(predStrengths, classLabels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    cur = (1.0,1.0) #cursor\n",
    "    # ySum用于计算AUC值\n",
    "    ySum = 0.0 #variable to calculate AUC\n",
    "    numPosClas = sum(array(classLabels)==1.0)\n",
    "    # 获取真、假样例总数\n",
    "    yStep = 1/float(numPosClas); xStep = 1/float(len(classLabels)-numPosClas)\n",
    "    # 将分类样例按照其预测强度进行排序，从排名最低的样例开始，所有排名更低的样例都被判别为反例，反则判别为正例\n",
    "    # 获取排好序的索引\n",
    "    sortedIndicies = predStrengths.argsort()#get sorted index, it's reverse\n",
    "    fig = plt.figure()\n",
    "    fig.clf()\n",
    "    ax = plt.subplot(111)\n",
    "    #loop through all the values, drawing a line segment at each point\n",
    "    # 如果该样例为正例，对真正率进行修改，如果该样例属于反例，就对假正率进行修改\n",
    "    for index in sortedIndicies.tolist()[0]:\n",
    "        if classLabels[index] == 1.0:\n",
    "            delX = 0; delY = yStep;\n",
    "        else:\n",
    "            delX = xStep; delY = 0;\n",
    "            ySum += cur[1]\n",
    "        #draw line from cur to (cur[0]-delX,cur[1]-delY)\n",
    "        ax.plot([cur[0],cur[0]-delX],[cur[1],cur[1]-delY], c='b')\n",
    "        cur = (cur[0]-delX,cur[1]-delY)\n",
    "    ax.plot([0,1],[0,1],'b--')\n",
    "    plt.xlabel('False positive rate'); plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve for AdaBoost horse colic detection system')\n",
    "    ax.axis([0,1,0,1])\n",
    "    plt.show()\n",
    "    print(\"the Area Under the Curve is: \",ySum*xStep)\n",
    "\n",
    "plotROC(aggClassEst.T,classLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b650755",
   "metadata": {},
   "source": [
    "# 基于代价函数的分类器决策控制\n",
    "### 除了调节分类器的阈值之外，还有一些其他用于处理非均衡分类代价的方法\n",
    "### 代价敏感学习：在AdaBoost中可以基于代价函数来调整错误权重向量D\n",
    "### 在SVM中可以在代价函数中对于不同类别选择不同的参数C\n",
    "### 在朴素贝叶斯中，可以选择具有最小期望代价而不是最大概率的类别作为最后结果\n",
    "\n",
    "\n",
    "# 处理非均衡问题的数据抽样方法\n",
    "### 对分类器的训练数据进行改造，可以通过欠抽样或者过抽样来实现\n",
    "### 欠抽样：意味着删除样例\n",
    "### 过抽样：意味着复制样例，复制已有样例或者加入已有样例相似的点，一种方法是加入已有数据点的插值点，可能会导致过拟合\n",
    "\n",
    "# 本章小结\n",
    "### 集成方法通过组合多个分类器的分类结果，获取比单分类更好的结果\n",
    "### bagging是通过随机抽样的替换方式，得到了与原始数据规模一样的数据集\n",
    "### boosting在bagging基础上，在数据集上顺序运用了多个不同的分类器\n",
    "### 随机森林也是一种集成学习方法\n",
    "### AdaBoost以弱学习器作为基分类器，并且输入数据，使其通过权重向量进行加权，第一次迭代时，所有数据都等权\n",
    "### 在后续迭代中，前次迭代中错分的数据的权重会增大，针对错误进行调节\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189927e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
